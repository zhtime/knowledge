## 时间复杂度的含义

**时间复杂度是一个函数，定性表述算法所需要的运行时间**

通过时间复杂度来估算程序运行所需的时间，常会估算算法的操作单元数量来代表程序消耗的时间，这里默认CPU的每个单元运行消耗的时间都是相同的。

假设算法的问题规模为n，那么操作单元数量便用函数f(n)来表示，随着数据规模n的增大，算法执行时间的增长率和f(n)的增长率相同，这称作为算法的渐近时间复杂度，简称时间复杂度，记为 O(f(n))。

### 大O

算法导论给出的解释：**大O用来表示上界的**，当用它作为算法的最坏情况运行时间的上界，就是对任意数据输入的运行时间的上界。



同样算法导论给出了例子：拿插入排序来说，插入排序的时间复杂度我们都说是O(n^2) 。

输入数据的形式对程序运算时间是有很大影响的，在数据本来有序的情况下时间复杂度是O(n)，但如果数据是逆序的话，插入排序的时间复杂度就是O(n^2)，也就对于所有输入情况来说，最坏是O(n^2) 的时间复杂度，所以称插入排序的时间复杂度为O(n^2)。

同样的同理再看一下快速排序，都知道快速排序是O(nlogn)，但是当数据已经有序情况下，快速排序的时间复杂度是O(n^2) 的，**所以严格从大O的定义来讲，快速排序的时间复杂度应该是O(n^2)**。



**但是我们依然说快速排序是O(nlogn)的时间复杂度，这个就是业内的一个默认规定，这里说的O代表的就是一般情况，而不是严格的上界**。如图所示：![image-20230111113119350](https://picturebedzhanghui.oss-cn-hangzhou.aliyuncs.com/img/202301111131448.png)

主要关心的是一般情况下的时间复杂度，包括在面试中一般也是这样。要记得一点：**数据用例的不一样，时间复杂度也是不同的**。

### 不同数据规模的差异

<img src="https://picturebedzhanghui.oss-cn-hangzhou.aliyuncs.com/img/202301111413372.png" alt="image-20230111141316238" style="zoom:50%;" />

由上图可知不同算法在不同数据规模下它的时间复杂度实在不断的变化的。

在决定使用哪些算法的时候，不是时间复杂越低的越好（因为简化后的时间复杂度忽略了常数项等等），要考虑数据规模，如果数据规模很小甚至可以用O(n^2)的算法比O(n)的更合适（在有常数项的时候）。

就像上图中 O(5n^2) 和 O(100n) 在n为20之前 很明显 O(5n^2)是更优的，所花费的时间也是最少的。

问题：**在计算时间复杂度时候为什么要忽略常数项系数呢，例如O(100n) 就是O(n)的时间复杂度，O(5n^2) 就是O(n^2)的时间复杂度，而且要默认O(n) 优于O(n^2) 呢 ？**

**根据大O的定义，因为大O就是数据量级突破一个点且数据量级非常大的情况下所表现出的时间复杂度，并且在这样庞大的数据量下常数项系数已经不能作为决定当前时间复杂度的主要因素**。例如：例如上图中20就是那个点，n只要大于20 常数项系数已经不起决定性作用了。

**所以通常我们所说的时间复杂度都是省略常数项系数，通常情况下一个算法的数据量规模是比较庞大的，基于这样的实事，给出各个算法时间复杂度排序：** **O(1)常数阶 < O(logn)对数阶 < O(n)线性阶 < O(n^2)平方阶 < O(n^3)立方阶 < O(2^n)指数阶**

需要注意的是：当常数项系数是很庞大的时，例如：10^7 ，10^9 ，那么常数就是不得不考虑的因素了。



### 复杂表达式的简化

通常计算时间复杂度需要经过一些列的化简，将一个复杂表达式进行化简。例如：

```text
O(2*n^2 + 10*n + 1000)
```

去掉运行时间中的加法常数项 （因为常数项并不会因为n的增大而增加计算机的操作次数）。

```text
O(2*n^2 + 10*n)
```

去掉常数系数（上文中已经详细讲过为什么可以去掉常数项的原因）。

```text
O(n^2 + n)
```

只保留保留最高项，去掉数量级小一级的n （因为n^2 的数据规模远大于n），最终简化为：

```text
O(n^2)
```

如果这一步理解有困难，那也可以做提取n的操作，变成O(n(n+1)) ，省略加法常数项后也就别变成了：

```text
O(n^2)
```

所以最后我们说：这个算法的算法时间复杂度是O(n^2) 。

### O(log n)中的log是以什么为底

通常说算法的时间复杂度会说时logn，它是一个对数，以什么为底呢？

可以是以10为底n的对数，也可以是以20为底n的对数，**但我们统一说 logn，也就是忽略底数的描述**。

下图解释：

<img src="https://picturebedzhanghui.oss-cn-hangzhou.aliyuncs.com/img/202301111438503.png" alt="image-20230111143856396" style="zoom:50%;" />

假如有两个算法的时间复杂度，分别是log以2为底n的对数和log以10为底n的对数，**根据对数换底公式![img](https://bkimg.cdn.bcebos.com/formula/5d15ca6663dd095990d7130a01fdd629.svg)结果如上图第一个公式可得。而以2为底10的对数是一个常数，可以忽略，抽象一下就是在时间复杂度的计算过程中，log以i为底n的对数等于log 以j为底n的对数，所以忽略了i，直接说是logn。**



### 举例

通过这道面试题目，来分析一下时间复杂度。题目描述：找出n个字符串中相同的两个字符串（假设这里只有两个相同的字符串）。

如果是暴力枚举的话，时间复杂度是多少呢，是O(n^2)么？

这里一些同学会忽略了字符串比较的时间消耗，这里并不像int 型数字做比较那么简单，除了n^2 次的遍历次数外，字符串比较依然要消耗m次操作（m也就是字母串的长度），所以时间复杂度是O(m × n × n)。

接下来再想一下其他解题思路。

先排对n个字符串按字典序来排序，排序后n个字符串就是有序的，意味着两个相同的字符串就是挨在一起，然后在遍历一遍n个字符串，这样就找到两个相同的字符串了。

那看看这种算法的时间复杂度，快速排序时间复杂度为O(nlogn)，依然要考虑字符串的长度是m，那么快速排序每次的比较都要有m次的字符比较的操作，就是O(m × n × log n) 。

之后还要遍历一遍这n个字符串找出两个相同的字符串，别忘了遍历的时候依然要比较字符串，所以总共的时间复杂度是 O(m × n × logn + n × m)。

我们对O(m × n × log n + n × m) 进行简化操作，把m × n提取出来变成 O(m × n × (logn + 1))，再省略常数项最后的时间复杂度是 O(m × n × log n)。

最后很明显O(m × n × logn) 要优于O(m × n × n)！

所以先把字符串集合排序再遍历一遍找到两个相同字符串的方法要比直接暴力枚举的方式更快。

这就是我们通过分析两种算法的时间复杂度得来的。

**当然这不是这道题目的最优解，我仅仅是用这道题目来讲解一下时间复杂度**

## 空间复杂度

**对一个算法在运行过程中所占用内存大小的度量，记做S(n)=O(f(n)）。**

空间复杂度(Space Complexity)记作S(n) 依然使用大O来表示。利用程序的空间复杂度，可以对程序运行中需要多少内存有个预先估计。

关注空间复杂度有两个常见的相关问题

1. 空间复杂度是考虑程序（可执行文件）的大小么？

   **空间复杂度是考虑程序运行时占用内存的大小，而不是可执行文件的大小。**

2. 空间复杂度是准确算出程序运行时所占用的内存么？

   空间复杂度并不能准确的估算出程序运行时所占据的内存大小，有很多因素会影响程序使用内存大小，例如**编译器的内存对齐，编程语言容器的底层实现**等等这些都会影响到程序内存的开销。

同样的工程实践中，计算机的内存资源不是无限的并且它不仅仅只为当前程序服务，它还服务于其他程序，因此空间复杂度是对程序使用内存的一个预估算，预估算是为了避免程序运行时超出内存限制OJ（Online judge）。

举例看看空间复杂度计算：

```java
int j = 0;
for (int i = 0; i < n; i++) {
    j++;
}
```

当前的空间复杂度为O(1),定义int类型变量j存储在内存中，而随着n的变化并没有开辟新的内存空间。

什么时候的空间复杂度是O(n)？

```java
int[] a = new int[n];
for (int i = 0; i < n; i++) {
    a[i] = i;
}
```

定义一个大小为n的数据，需要分配n的内存空间，随着n的不断增大所需要的空间成线性增长，因此当前程序的空间复杂度为O(n)。

其他的 O(n^2)， O(n^3) 可以以此例子举例。

## 内存消耗

不同的编程语言各自的内存管理方式。

- C/C++这种内存堆空间的申请和释放完全靠自己管理
- Java 依赖JVM来做内存管理，不了解jvm内存管理的机制，很可能会因一些错误的代码写法而导致内存泄漏或内存溢出
- Python内存管理是由私有堆空间管理的，所有的python对象和数据结构都存储在私有堆空间中。程序员没有访问堆的权限，只有解释器才能操作。

### 内存对齐

内存管理中重要知识点：**内存对齐**

**只要可以跨平台的编程语言都需要做内存对齐，c++、Java、Python都是一样的**。

**为什么会有内存对齐？**

1. 平台原因:不是所有硬件平台都能无限制的访问内存地址上的任意数据，有些硬件平台只能在特定内存地址处访问特定的数据，否则抛出硬件异常。为了同一程序可以在多个平台上运行，需要内存对齐。
2. 硬件原因：经过内存对齐后，cpu访问速度大大提升。

**内存对齐和非内存对齐产生的效果区别**

CPU读取内存不是一次读取单个字节，而是一块一块的来读取内存，块的大小可以是2，4，8，16个字节，具体取多少个字节取决于硬件。

假设CPU把内存划分为4字节大小的块，要读取一个4字节大小的int型数据，来看一下这两种情况下CPU的工作量：

第一种就是内存对齐的情况，如图：

![image-20230111151109763](https://picturebedzhanghui.oss-cn-hangzhou.aliyuncs.com/img/202301111511880.png)

一字节的char占用了四个字节，空了三个字节的内存地址，int数据从地址4开始。

此时，直接将地址4，5，6，7处的四个字节数据读取到即可。



第二种是没有内存对齐的情况如图：

<img src="https://picturebedzhanghui.oss-cn-hangzhou.aliyuncs.com/img/202301111512778.png" alt="image-20230111151202664" style="zoom:80%;" />

char型的数据和int型的数据挨在一起，该int数据从地址1开始，那么CPU想要读这个数据的话来看看需要几步操作：

1. 因为CPU是四个字节四个字节来寻址，首先CPU读取0，1，2，3处的四个字节数据
2. CPU读取4，5，6，7处的四个字节数据
3. 合并地址1，2，3，4处四个字节的数据才是本次操作需要的int数据

此时一共需要两次寻址，一次合并的操作。

**大家可能会发现内存对齐岂不是浪费的内存资源么？**

是这样的，但事实上，相对来说计算机内存资源一般都是充足的，我们更希望的是提高运行速度。

**编译器一般都会做内存对齐的优化操作，也就是说当考虑程序真正占用的内存大小的时候，也需要认识到内存对齐的影响**。